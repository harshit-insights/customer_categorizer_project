{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcaaa546",
   "metadata": {},
   "source": [
    "# Classifiction after clustering with K-Means clusttering:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b442c0",
   "metadata": {},
   "source": [
    "#### Import Clusterd dataset and modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bedcaf6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2240, 22)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.pandas.set_option(\"display.max_columns\", None)\n",
    "# create dataframe:\n",
    "df = pd.read_csv(r\"./data/clustered_data.csv\")\n",
    "# print the shape of dataset:\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b2e4b8",
   "metadata": {},
   "source": [
    "**Split X and y**\n",
    "- Why do we split our data?\n",
    "> Training Dataset is the part of Original Dataset that we use to train our ML model. The model learns on this data by running the algorithm and maps a function F(x) where “x” in the independent variable (inputs) for “y” where “y” is the dependent variable(output)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0bdff1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('cluster', axis = 1) # droping the target column whic is cluster.\n",
    "y = df['cluster']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75282558",
   "metadata": {},
   "source": [
    "## Grid Search\n",
    "\n",
    "- Why do we use Grid Search?\n",
    "\n",
    "`GridSearchCV` is a technique to search through the best parameter values from the given set of the grid of parameters. It is basically a cross-validation method. the model and the parameters are required to be fed in. Best parameter values are extracted and then the predictions are made."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d9ea99",
   "metadata": {},
   "source": [
    "## Select the best model\n",
    "- so here we have some list of the best classification algorithms we imported. Now we will compare each model's score and see which model is performing better than rest of the others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80f97189",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC # support vector classifier.\n",
    "from sklearn.metrics import accuracy_score, classification_report,ConfusionMatrixDisplay, \\\n",
    "                            precision_score, recall_score, f1_score, roc_auc_score,roc_curve,confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"K-Neighbors Classifier\": KNeighborsClassifier(),\n",
    "    \"XGBClassifier\": XGBClassifier(),\n",
    "    \"CatBoosting Classifier\": CatBoostClassifier(verbose=False),\n",
    "    \"AdaBoost Classifier\": AdaBoostClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ce084a",
   "metadata": {},
   "source": [
    "- #####  We will create a generic function to check each model's performance so that we can compare those:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a53e574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function which can evaluate models and return a report\n",
    "def evaluate_models(X, y, models):\n",
    "    '''\n",
    "    This function takes in X and y and models dictionary as input\n",
    "    It splits the data into Train Test split\n",
    "    Iterates through the given model dictionary and evaluates the metrics\n",
    "    Returns: Dataframe which contains report of all models metrics with cost\n",
    "    '''\n",
    "    # separate dataset into train and test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "    models_list = []\n",
    "    scores = []\n",
    "    for i in range(len(list(models))):\n",
    "        model = list(models.values())[i]\n",
    "        model.fit(X_train, y_train) # Train model\n",
    "\n",
    "        # Make predictions\n",
    "        y_pred = model.predict(X_test)\n",
    "        score = accuracy_score(y_test,y_pred)\n",
    "        model_name = list(models.keys())[i]\n",
    "        print(f'---- score for --- {model_name} ----')\n",
    "        print(f\"{score}\")\n",
    "        models_list.append(model_name)\n",
    "        scores.append(score)\n",
    "    print()\n",
    "    report = pd.DataFrame()\n",
    "    report['Model_name'] = models_list\n",
    "    report['Score'] = score\n",
    "    return report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52c7858",
   "metadata": {},
   "source": [
    "### Let's check the report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "300a716d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- score for --- Random Forest ----\n",
      "0.9642857142857143\n",
      "---- score for --- Decision Tree ----\n",
      "0.9441964285714286\n",
      "---- score for --- Gradient Boosting ----\n",
      "0.9553571428571429\n",
      "---- score for --- Logistic Regression ----\n",
      "0.8772321428571429\n",
      "---- score for --- K-Neighbors Classifier ----\n",
      "0.8102678571428571\n",
      "---- score for --- XGBClassifier ----\n",
      "0.9553571428571429\n",
      "---- score for --- CatBoosting Classifier ----\n",
      "0.9665178571428571\n",
      "---- score for --- AdaBoost Classifier ----\n",
      "0.9464285714285714\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = evaluate_models(X, y, models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf93e41",
   "metadata": {},
   "source": [
    "- ### From the report above we can see that the logistic regression model performed the best, so we will continue training our model using logistic regression algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2734fb3",
   "metadata": {},
   "source": [
    "### Split into Train and test data\n",
    "\n",
    "- **Do you know why we split the train and test dataset?**\n",
    "> The train test split technique can be used for classification and regression problems to test machine learning algorithms. The procedure takes the given dataset and splits it into two subsets: ```Training data/train set:``` it is used to train the algorithm and fit the machine learning model\n",
    "then we have ```test data/test set``` which is basically a different data for which we know the values but this data was never shown to the model before. Thus if the model after training is performing good on test set as well then we can say that the Machine Learning model is good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "441a5827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>Parental Status</th>\n",
       "      <th>Children</th>\n",
       "      <th>Income</th>\n",
       "      <th>Total_Spending</th>\n",
       "      <th>Days_as_Customer</th>\n",
       "      <th>Recency</th>\n",
       "      <th>Wines</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>Meat</th>\n",
       "      <th>Fish</th>\n",
       "      <th>Sweets</th>\n",
       "      <th>Gold</th>\n",
       "      <th>Web</th>\n",
       "      <th>Catalog</th>\n",
       "      <th>Store</th>\n",
       "      <th>Discount Purchases</th>\n",
       "      <th>Total Promo</th>\n",
       "      <th>NumWebVisitsMonth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>68.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>64587.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>4260.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2162</th>\n",
       "      <td>65.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>47320.0</td>\n",
       "      <td>414.0</td>\n",
       "      <td>4585.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>61.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>86429.0</td>\n",
       "      <td>1449.0</td>\n",
       "      <td>4473.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>464.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>556.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>44.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38593.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>4542.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1877</th>\n",
       "      <td>64.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72905.0</td>\n",
       "      <td>1515.0</td>\n",
       "      <td>4412.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>407.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>445.0</td>\n",
       "      <td>120.5</td>\n",
       "      <td>81.0</td>\n",
       "      <td>126.5</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1638</th>\n",
       "      <td>53.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>44078.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>4263.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>43.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>61825.0</td>\n",
       "      <td>424.0</td>\n",
       "      <td>4579.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>71.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>67381.0</td>\n",
       "      <td>957.0</td>\n",
       "      <td>4783.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>815.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>59.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>48918.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>4331.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>53.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23228.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>4407.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1568 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Age  Education  Marital Status  Parental Status  Children   Income  \\\n",
       "994   68.0          2               0                1         2  64587.0   \n",
       "2162  65.0          2               1                1         1  47320.0   \n",
       "906   61.0          2               0                0         0  86429.0   \n",
       "572   44.0          1               0                1         1  38593.0   \n",
       "1877  64.0          2               1                0         0  72905.0   \n",
       "...    ...        ...             ...              ...       ...      ...   \n",
       "1638  53.0          2               1                1         2  44078.0   \n",
       "1095  43.0          2               0                1         1  61825.0   \n",
       "1130  71.0          3               1                1         1  67381.0   \n",
       "1294  59.0          4               0                1         2  48918.0   \n",
       "860   53.0          2               1                1         1  23228.0   \n",
       "\n",
       "      Total_Spending  Days_as_Customer  Recency  Wines  Fruits   Meat   Fish  \\\n",
       "994            108.0            4260.0     49.0   66.0     0.0   16.0    0.0   \n",
       "2162           414.0            4585.0     10.0  200.0    19.0  111.0   50.0   \n",
       "906           1449.0            4473.0     10.0  464.0    28.0  556.0   29.0   \n",
       "572            177.0            4542.0     42.0   51.0    12.0   49.0   17.0   \n",
       "1877          1515.0            4412.0     52.0  407.0    81.0  445.0  120.5   \n",
       "...              ...               ...      ...    ...     ...    ...    ...   \n",
       "1638            41.0            4263.0     17.0   24.0     1.0   10.0    2.0   \n",
       "1095           424.0            4579.0     56.0  162.0    50.0  100.0   55.0   \n",
       "1130           957.0            4783.0     67.0  815.0     8.0   53.0   11.0   \n",
       "1294            62.0            4331.0     21.0   52.0     0.0    9.0    0.0   \n",
       "860             40.0            4407.0     71.0   13.0     2.0   18.0    6.0   \n",
       "\n",
       "      Sweets   Gold  Web  Catalog  Store  Discount Purchases  Total Promo  \\\n",
       "994      6.0   20.0    1        1      4                   2            0   \n",
       "2162    15.0   19.0    5        1      8                   6            0   \n",
       "906     18.0   37.0    7        4      7                   0            2   \n",
       "572     24.0   24.0    4        1      3                   3            0   \n",
       "1877    81.0  126.5    3        7      9                   1            1   \n",
       "...      ...    ...  ...      ...    ...                 ...          ...   \n",
       "1638     0.0    4.0    2        0      3                   2            0   \n",
       "1095    30.0   27.0    4        2      8                   1            0   \n",
       "1130     0.0   70.0    2        2      9                   4            1   \n",
       "1294     0.0    1.0    1        0      4                   2            0   \n",
       "860      1.0    0.0    2        0      3                   2            0   \n",
       "\n",
       "      NumWebVisitsMonth  \n",
       "994                   3  \n",
       "2162                  6  \n",
       "906                   2  \n",
       "572                   8  \n",
       "1877                  1  \n",
       "...                 ...  \n",
       "1638                  5  \n",
       "1095                  4  \n",
       "1130                  7  \n",
       "1294                  4  \n",
       "860                   8  \n",
       "\n",
       "[1568 rows x 21 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.3)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48aa979e",
   "metadata": {},
   "source": [
    "### Let's do hyperparameter tuning\n",
    "- **And what's it actually?**\n",
    "\n",
    "> A Machine Learning model is defined as a mathematical model with a number of parameters that need to be learned from the data. By training a model with existing data, we are able to fit the model parameters. \n",
    "However, there is another kind of parameter, known as Hyperparameters, that cannot be directly learned from the regular training process. They are usually fixed before the actual training process begins. These parameters express important properties of the model such as its complexity or how fast it should learn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e3636bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned hpyerparameters :(best parameters)  {'C': np.float64(1.0), 'max_iter': np.int32(175), 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "accuracy : 0.9821370243344765\n"
     ]
    }
   ],
   "source": [
    "# Grid search cross validation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "    'max_iter': np.random.randint(100,500, 10),\n",
    "    \"C\":np.logspace(-3,3,7),\n",
    "    \"penalty\":[\"l1\",\"l2\"]\n",
    "}\n",
    "\n",
    "logreg=LogisticRegression()\n",
    "\n",
    "logreg_cv=GridSearchCV(logreg,params,cv=10, n_jobs=-1)\n",
    "logreg_cv.fit(X_train,y_train)\n",
    "\n",
    "print(\"tuned hpyerparameters :(best parameters) \",logreg_cv.best_params_)\n",
    "print(\"accuracy :\",logreg_cv.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02bbd5c",
   "metadata": {},
   "source": [
    "### So we got our best parameters. Let's now train the model with those parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10694c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lr_model = LogisticRegression(\n",
    "    C = 1000,\n",
    "    max_iter =  113,\n",
    "    penalty =  'l2',\n",
    "    solver =  'lbfgs'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59d356c",
   "metadata": {},
   "source": [
    "**Initialize model with best parameters**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33a1d48",
   "metadata": {},
   "source": [
    "### Let's check the report now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d289819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression\n",
      "Accuracy Score value: 0.8735\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96       259\n",
      "           1       0.81      0.84      0.82       237\n",
      "           2       0.82      0.81      0.81       176\n",
      "\n",
      "    accuracy                           0.87       672\n",
      "   macro avg       0.87      0.87      0.87       672\n",
      "weighted avg       0.88      0.87      0.87       672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_model = best_lr_model.fit(X_train,y_train)\n",
    "y_pred = best_model.predict(X_test)\n",
    "score = accuracy_score(y_test,y_pred)\n",
    "cr = classification_report(y_test,y_pred)\n",
    "\n",
    "print(\"Logistic regression\")\n",
    "print (\"Accuracy Score value: {:.4f}\".format(score))\n",
    "print (cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b9d5fd",
   "metadata": {},
   "source": [
    "## Confusion matrix of the model\n",
    "- **What is confusion matrix ?**\n",
    "> The confusion matrix is a matrix used to determine the performance of the classification models for a given set of test data. It can only be determined if the true values for test data are known. The matrix itself can be easily understood, but the related terminologies may be confusing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3be226d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x28c7fccb4d0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ConfusionMatrixDisplay.from_estimator(best_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7820d27b",
   "metadata": {},
   "source": [
    "## Confusion matrix of the model\n",
    "- **What is confusion matrix ?**\n",
    "> The confusion matrix is a matrix used to determine the performance of the classification models for a given set of test data. It can only be determined if the true values for test data are known. The matrix itself can be easily understood, but the related terminologies may be confusing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c51423c",
   "metadata": {},
   "source": [
    "- **Reports**\n",
    "\n",
    "**We can see, that the model performed pretty well.**\n",
    "- we have used logistic regression as it performed well than other models\n",
    "- We got a good accuracy while predicting the test dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "customer_categorizer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
